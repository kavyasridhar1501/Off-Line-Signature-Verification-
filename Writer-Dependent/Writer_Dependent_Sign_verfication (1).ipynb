{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Writer_Dependent_Sign_verfication",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "MOUNTING GOOGLE DRIVE"
      ],
      "metadata": {
        "id": "6IrMtHuik6jZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwXba8Cnk1Sq",
        "outputId": "9579589b-b1f1-417d-ff60-1bd490b6b4b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive not mounted, so nothing to flush and unmount.\n",
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.flush_and_unmount()\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "IMPORTING LIBRARIES"
      ],
      "metadata": {
        "id": "YYT6M7ialF7T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import matplotlib.cm as cm\n",
        "from scipy import ndimage\n",
        "from skimage.measure import regionprops\n",
        "from skimage import io\n",
        "from skimage.filters import threshold_otsu   # helps find the threshold for grayscale to binary conversion of images\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from time import time\n",
        "import keras"
      ],
      "metadata": {
        "id": "ej6vfgX_lKm8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEIFINING PATHS TO REAL & FORGED DATASET"
      ],
      "metadata": {
        "id": "lGkeE8KBlZuV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genuine_image_paths = \"drive/MyDrive/ML MINI PROJECT/real\"\n",
        "forged_image_paths = \"drive/MyDrive/ML MINI PROJECT/forged\""
      ],
      "metadata": {
        "id": "djNZ_1nqlY73"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PREPROCESSING"
      ],
      "metadata": {
        "id": "yYWN78B6mLyl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Converts RGB to Gray Scale"
      ],
      "metadata": {
        "id": "6Fupn_qzmUnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rgbgrey(img):\n",
        "    greyimg = np.zeros((img.shape[0], img.shape[1]))\n",
        "    for row in range(len(img)):\n",
        "        for col in range(len(img[row])):\n",
        "            greyimg[row][col] = np.average(img[row][col])\n",
        "    return greyimg"
      ],
      "metadata": {
        "id": "ivOIrq4VmOUz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Converts  Gray Scale to Binary"
      ],
      "metadata": {
        "id": "LTGTSDQZmfTS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def greybin(img):\n",
        "  blur_radius = 0.8\n",
        "  img = ndimage.gaussian_filter(img, blur_radius)  \n",
        "  thres = threshold_otsu(img)\n",
        "  binimg = img > thres\n",
        "  binimg = np.logical_not(binimg)\n",
        "  return binimg"
      ],
      "metadata": {
        "id": "KGQLYmM_mjqp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Preprocessing Function"
      ],
      "metadata": {
        "id": "c47SRxWrnB9j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preproc(path, img=None, display=True):\n",
        "    if img is None:\n",
        "        img = mpimg.imread(path)\n",
        "    if display:\n",
        "        plt.imshow(img)\n",
        "        plt.show()\n",
        "    grey = rgbgrey(img) #coverting to gray scale\n",
        "    if display:\n",
        "        plt.imshow(grey, cmap = matplotlib.cm.Greys_r)\n",
        "        plt.show()\n",
        "    binimg = greybin(grey) #coverting to binary\n",
        "    if display:\n",
        "        plt.imshow(binimg, cmap = matplotlib.cm.Greys_r)\n",
        "        plt.show()\n",
        "    r, c = np.where(binimg==1)\n",
        "    # Now we will make a bounding box with the boundary as the position of pixels on extreme.\n",
        "    # Thus we will get a cropped image with only the signature part.\n",
        "    signimg = binimg[r.min(): r.max(), c.min(): c.max()]\n",
        "    if display:\n",
        "        plt.imshow(signimg, cmap = matplotlib.cm.Greys_r)\n",
        "        plt.show()\n",
        "    return signimg"
      ],
      "metadata": {
        "id": "xQGIRd0rnYTF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "FEATURE EXTRACTION"
      ],
      "metadata": {
        "id": "rJ2g0oBJn4Rf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def Ratio(img):\n",
        "    a = 0\n",
        "    for row in range(len(img)):\n",
        "        for col in range(len(img[0])):\n",
        "            if img[row][col]==True:\n",
        "                a = a+1\n",
        "    total = img.shape[0] * img.shape[1]\n",
        "    return a/total"
      ],
      "metadata": {
        "id": "ud25Gg-Xn7Cu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Centroid(img):\n",
        "    numOfWhites = 0\n",
        "    a = np.array([0,0])\n",
        "    for row in range(len(img)):\n",
        "        for col in range(len(img[0])):\n",
        "            if img[row][col]==True:\n",
        "                b = np.array([row,col])\n",
        "                a = np.add(a,b)\n",
        "                numOfWhites += 1\n",
        "    rowcols = np.array([img.shape[0], img.shape[1]])\n",
        "    centroid = a/numOfWhites\n",
        "    centroid = centroid/rowcols\n",
        "    return centroid[0], centroid[1]"
      ],
      "metadata": {
        "id": "baKTEGfTn_Km"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def EccentricitySolidity(img):\n",
        "    r = regionprops(img.astype(\"int8\"))\n",
        "    return r[0].eccentricity, r[0].solidity"
      ],
      "metadata": {
        "id": "mmXeymMaoCDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def SkewKurtosis(img):\n",
        "    h,w = img.shape\n",
        "    x = range(w)  # cols value\n",
        "    y = range(h)  # rows value\n",
        "    #calculate projections along the x and y axes\n",
        "    xp = np.sum(img,axis=0)\n",
        "    yp = np.sum(img,axis=1)\n",
        "    #centroid\n",
        "    cx = np.sum(x*xp)/np.sum(xp)\n",
        "    cy = np.sum(y*yp)/np.sum(yp)\n",
        "    #standard deviation\n",
        "    x2 = (x-cx)**2\n",
        "    y2 = (y-cy)**2\n",
        "    sx = np.sqrt(np.sum(x2*xp)/np.sum(img))\n",
        "    sy = np.sqrt(np.sum(y2*yp)/np.sum(img))\n",
        "    \n",
        "    #skewness\n",
        "    x3 = (x-cx)**3\n",
        "    y3 = (y-cy)**3\n",
        "    skewx = np.sum(xp*x3)/(np.sum(img) * sx**3)\n",
        "    skewy = np.sum(yp*y3)/(np.sum(img) * sy**3)\n",
        "\n",
        "    #Kurtosis\n",
        "    x4 = (x-cx)**4\n",
        "    y4 = (y-cy)**4\n",
        "    # 3 is subtracted to calculate relative to the normal distribution\n",
        "    kurtx = np.sum(xp*x4)/(np.sum(img) * sx**4) - 3\n",
        "    kurty = np.sum(yp*y4)/(np.sum(img) * sy**4) - 3\n",
        "\n",
        "    return (skewx , skewy), (kurtx, kurty)"
      ],
      "metadata": {
        "id": "HxjUIKTloFId"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getFeatures(path, img=None, display=False):\n",
        "    if img is None:\n",
        "        img = mpimg.imread(path)\n",
        "    img = preproc(path, display=display)\n",
        "    ratio = Ratio(img)\n",
        "    centroid = Centroid(img)\n",
        "    eccentricity, solidity = EccentricitySolidity(img)\n",
        "    skewness, kurtosis = SkewKurtosis(img)\n",
        "    retVal = (ratio, centroid, eccentricity, solidity, skewness, kurtosis)\n",
        "    return retVal"
      ],
      "metadata": {
        "id": "8RFqw5qioKxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def getCSVFeatures(path, img=None, display=False):\n",
        "    if img is None:\n",
        "        img = mpimg.imread(path)\n",
        "    temp = getFeatures(path, display=display)\n",
        "    features = (temp[0], temp[1][0], temp[1][1], temp[2], temp[3], temp[4][0], temp[4][1], temp[5][0], temp[5][1])\n",
        "    return features"
      ],
      "metadata": {
        "id": "Z0B5rb-EoNVh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SAVING THE EXTRACTED FEATURES"
      ],
      "metadata": {
        "id": "LrbZlAsWoO5V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def makeCSV():\n",
        "    if not(os.path.exists('drive/MyDrive/ML MINI PROJECT/FEATURES')):\n",
        "        os.mkdir('drive/MyDrive/ML MINI PROJECT/FEATURES')\n",
        "        print('New folder \"FEATURES\" created')\n",
        "    if not(os.path.exists('drive/MyDrive/ML MINI PROJECT/FEATURES/Training')):\n",
        "        os.mkdir('drive/MyDrive/ML MINI PROJECT/FEATURES/Training')\n",
        "        print('New folder \"FEATURES/Training\" created')\n",
        "    if not(os.path.exists('drive/MyDrive/ML MINI PROJECT/FEATURES/Testing')):\n",
        "        os.mkdir('drive/MyDrive/ML MINI PROJECT/FEATURES/Testing')\n",
        "        print('New folder \"FEATURES/Testing\" created')\n",
        "     \n",
        "    gpath = genuine_image_paths\n",
        "     \n",
        "    fpath = forged_image_paths\n",
        "    \n",
        "    for person in range(1,13):\n",
        "        per = ('00'+str(person))[-3:]\n",
        "        print('Saving extracted features of Person-',per)\n",
        "        \n",
        "        with open('drive/MyDrive/ML MINI PROJECT/FEATURES/Training/training_'+per+'.csv', 'w') as handle:\n",
        "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
        "            # Training set\n",
        "            for i in range(0,3):\n",
        "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                handle.write(','.join(map(str, features))+',1\\n')\n",
        "            for i in range(0,3):\n",
        "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                handle.write(','.join(map(str, features))+',0\\n')\n",
        "        \n",
        "        with open('drive/MyDrive/ML MINI PROJECT/FEATURES/Testing/testing_'+per+'.csv', 'w') as handle:\n",
        "            handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y,output\\n')\n",
        "            # Testing set\n",
        "            for i in range(3, 5):\n",
        "                source = os.path.join(gpath, per+per+'_00'+str(i)+'.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                handle.write(','.join(map(str, features))+',1\\n')\n",
        "            for i in range(3,5):\n",
        "                source = os.path.join(fpath, '021'+per+'_00'+str(i)+'.png')\n",
        "                features = getCSVFeatures(path=source)\n",
        "                handle.write(','.join(map(str, features))+',0\\n')"
      ],
      "metadata": {
        "id": "ar216uJuoRU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "makeCSV()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4ZYimKRp_9A",
        "outputId": "76115c83-c8ad-4344-a0d6-97795289f56c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving extracted features of Person- 001\n",
            "Saving extracted features of Person- 002\n",
            "Saving extracted features of Person- 003\n",
            "Saving extracted features of Person- 004\n",
            "Saving extracted features of Person- 005\n",
            "Saving extracted features of Person- 006\n",
            "Saving extracted features of Person- 007\n",
            "Saving extracted features of Person- 008\n",
            "Saving extracted features of Person- 009\n",
            "Saving extracted features of Person- 010\n",
            "Saving extracted features of Person- 011\n",
            "Saving extracted features of Person- 012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MODEL"
      ],
      "metadata": {
        "id": "yQSPkAs1remX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import utils as np_utils"
      ],
      "metadata": {
        "id": "pt6zAPj4Xz2B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def testing(path):\n",
        "    feature = getCSVFeatures(path)\n",
        "    if not(os.path.exists('drive/MyDrive/ML MINI PROJECT/TestFeatures')):\n",
        "        os.mkdir('drive/MyDrive/ML MINI PROJECT/TestFeatures')\n",
        "    with open('drive/MyDrive/ML MINI PROJECT/TestFeatures/testcsv.csv', 'w') as handle:\n",
        "        handle.write('ratio,cent_y,cent_x,eccentricity,solidity,skew_x,skew_y,kurt_x,kurt_y\\n')\n",
        "        handle.write(','.join(map(str, feature))+'\\n')"
      ],
      "metadata": {
        "id": "9fNzv5PLrf80"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_input = 9\n",
        "train_person_id = input(\"Enter person's id : \")\n",
        "test_image_path = input(\"Enter path of signature image : \")\n",
        "train_path = 'drive/MyDrive/ML MINI PROJECT/FEATURES/Training/training_'+train_person_id+'.csv'\n",
        "testing(test_image_path)\n",
        "test_path = 'drive/MyDrive/ML MINI PROJECT/TestFeatures/testcsv.csv'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cpI7JTgfTibL",
        "outputId": "5a8d1801-efe0-4469-9f6a-587baaee4c84"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter person's id : 001\n",
            "Enter path of signature image : drive/MyDrive/ML MINI PROJECT/real/001001_001.png\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readCSV(train_path, test_path, type2=False):\n",
        "    # Reading train data\n",
        "    df = pd.read_csv(train_path, usecols=range(n_input))\n",
        "    train_input = np.array(df.values)\n",
        "    train_input = train_input.astype(np.float32, copy=False)  # Converting input to float_32\n",
        "    df = pd.read_csv(train_path, usecols=(n_input,))\n",
        "    temp = [elem[0] for elem in df.values]\n",
        "    correct = np.array(temp)\n",
        "    corr_train = keras.utils.np_utils.to_categorical(correct,2)      # Converting to one hot\n",
        "    # Reading test data\n",
        "    df = pd.read_csv(test_path, usecols=range(n_input))\n",
        "    test_input = np.array(df.values)\n",
        "    test_input = test_input.astype(np.float32, copy=False)\n",
        "    if not(type2):\n",
        "        df = pd.read_csv(test_path, usecols=(n_input,))\n",
        "        temp = [elem[0] for elem in df.values]\n",
        "        correct = np.array(temp)\n",
        "        corr_test = keras.utils.np_utils.to_categorical(correct,2)      # Converting to one hot\n",
        "    if not(type2):\n",
        "        return train_input, corr_train, test_input, corr_test\n",
        "    else:\n",
        "        return train_input, corr_train, test_input"
      ],
      "metadata": {
        "id": "QE0bs4jRVavu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.compat.v1.disable_eager_execution()"
      ],
      "metadata": {
        "id": "TSPPPYFcZBW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DEFINING IMPORTANT PARAMETERS FOR THE MLP MODEL"
      ],
      "metadata": {
        "id": "whyzMdp3s6dj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = 0.1\n",
        "training_epochs = 100\n",
        "cost_history = np.empty(shape=[1], dtype=float)\n",
        "n_dim = 9\n",
        "n_class = 2 #two possible output\n",
        "print(n_dim)\n",
        "\n",
        "#define the number of hidden layers and number of neurons for each layer\n",
        "n_hidden_1 = 60\n",
        "n_hidden_2 = 60\n",
        "n_hidden_3 = 60\n",
        "n_hidden_4 = 60\n",
        "\n",
        "x = tf.compat.v1.placeholder(tf.float32, [None, n_dim])\n",
        "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
        "b = tf.Variable(tf.zeros([n_class]))\n",
        "y_ = tf.compat.v1.placeholder(tf.float32, [None, n_class])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgb6K3oHP_9g",
        "outputId": "18c8ff82-7613-44bf-b767-7351701a27f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "MLP MODEL  (sigmoid activation function)"
      ],
      "metadata": {
        "id": "m8pF7RJztHtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multilayer_perceptron(x, weights, biases):\n",
        "  # Input layer \n",
        "  layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
        "  layer_1 = tf.nn.sigmoid(layer_1)\n",
        "  # Hidden layer \n",
        "  layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
        "  layer_2 = tf.nn.sigmoid(layer_2)\n",
        "  # Hidden layer \n",
        "  layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
        "  layer_3 = tf.nn.sigmoid(layer_3)\n",
        "  # Hidden layer \n",
        "  layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
        "  layer_4 = tf.nn.sigmoid(layer_4)\n",
        "  # Output layer \n",
        "  out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
        "  return out_layer"
      ],
      "metadata": {
        "id": "QpzD1e86RVLQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Weights and Biases "
      ],
      "metadata": {
        "id": "NhBVh5l1tc-A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "weights = {\n",
        "  'h1': tf.Variable(tf.compat.v1.truncated_normal([n_dim, n_hidden_1])),\n",
        "  'h2': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_1, n_hidden_2])),\n",
        "  'h3': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_2, n_hidden_3])),\n",
        "  'h4': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_3, n_hidden_4])),\n",
        "  'out': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_4, n_class]))\n",
        "}\n",
        "biases = {\n",
        "  'b1': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_1])),\n",
        "  'b2': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_2])),\n",
        "  'b3': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_3])),\n",
        "  'b4': tf.Variable(tf.compat.v1.truncated_normal([n_hidden_4])),\n",
        "  'out': tf.Variable(tf.compat.v1.truncated_normal([n_class]))\n",
        "} "
      ],
      "metadata": {
        "id": "4HCtGu0FRyNw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#initialize \n",
        "init = tf.compat.v1.global_variables_initializer()\n",
        "\n",
        "y = multilayer_perceptron(x, weights, biases)\n",
        "#Cost function \n",
        "cost_function = tf.reduce_mean(tf.compat.v1.nn.softmax_cross_entropy_with_logits_v2(logits=y, labels=y_))\n",
        "training_step = tf.compat.v1.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
        "sess = tf.compat.v1.Session()\n",
        "sess.run(init)"
      ],
      "metadata": {
        "id": "mIJhAjeOSUrF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define loss and Optimizer\n",
        "loss_op = tf.reduce_mean(tf.compat.v1.squared_difference(y, y_))\n",
        "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
        "train_op = optimizer.minimize(loss_op)\n",
        "# For accuracies\n",
        "pred = tf.nn.softmax(y)  # Apply softmax to logits\n",
        "correct_prediction = tf.equal(tf.argmax(pred,1), tf.argmax(y_,1))\n",
        "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
        "# Initializing the variables\n",
        "init = tf.compat.v1.global_variables_initializer()"
      ],
      "metadata": {
        "id": "KdO8iC7yV_lT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(train_path, test_path, type2=False):   \n",
        "    if not(type2):\n",
        "        train_input, corr_train, test_input, corr_test = readCSV(train_path, test_path)\n",
        "    else:\n",
        "        train_input, corr_train, test_input = readCSV(train_path, test_path, type2)\n",
        "    ans = 'Random'\n",
        "    with tf.compat.v1.Session() as sess:\n",
        "        sess.run(init)\n",
        "        # Training cycle\n",
        "        for epoch in range(training_epochs):\n",
        "            # Run optimization op (backprop) and cost op (to get loss value)\n",
        "            _, cost = sess.run([train_op, loss_op], feed_dict={x: train_input, y_: corr_train})\n",
        "            if cost<0.0001:\n",
        "                break      \n",
        "        # Finding accuracies\n",
        "        accuracy1 =  accuracy.eval({x: train_input, y_: corr_train})\n",
        "        print(\"Accuracy for training model:\", accuracy1)\n",
        "        prediction = pred.eval({x: test_input})\n",
        "        \n",
        "        if prediction[0][1]>prediction[0][0]:\n",
        "            print('Genuine Image')\n",
        "            return True\n",
        "        else:\n",
        "            print('Forged Image')\n",
        "            return False"
      ],
      "metadata": {
        "id": "2OOe7PsgWQOk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(train_path, test_path, type2=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qkLZAfX7WcBS",
        "outputId": "8f068f74-00d8-41a8-ced4-78df0b69b07b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy for training model: 0.5\n",
            "Genuine Image\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 171
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sample Paths to Test"
      ],
      "metadata": {
        "id": "GpTcNdY7tvIg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#real: drive/MyDrive/ML MINI PROJECT/real/001001_001.png\n",
        "#forged: drive/MyDrive/ML MINI PROJECT/forged/021001_001.png"
      ],
      "metadata": {
        "id": "Wjk9ce9KykJ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}